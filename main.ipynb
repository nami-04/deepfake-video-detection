{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rfDE2Fe4_DWU"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!pip install opencv-contrib-python\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#!pip install imageio\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-contrib-python\n",
    "#!pip install imageio\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5392,
     "status": "ok",
     "timestamp": 1683028912398,
     "user": {
      "displayName": "pantech e learning",
      "userId": "02085171050783995221"
     },
     "user_tz": -330
    },
    "id": "RNdy2X8-_DWW",
    "outputId": "552ddc74-086a-4f9f-eb1c-a6f8c0bc203d"
   },
   "outputs": [],
   "source": [
    "#data='C:/Users/HP/Music/deepfake/dataset/train_sample_videos'\n",
    "DATA_FOLDER = r'path\\to\\dataset'\n",
    "TRAIN_SAMPLE_FOLDER =  r'path\\to\\train_sample_videos'\n",
    "TEST_FOLDER =r'path\\to\\test_videos'\n",
    "\n",
    "print(f\"train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\n",
    "print(f\"test samples: {len(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1683028915616,
     "user": {
      "displayName": "pantech e learning",
      "userId": "02085171050783995221"
     },
     "user_tz": -330
    },
    "id": "1xiJbdB-_DWY",
    "outputId": "159bca67-71f4-4426-c392-cdf064c93d1e"
   },
   "outputs": [],
   "source": [
    "train_sample_metadata = pd.read_json(r'path\\to\\metadata.json').T\n",
    "train_sample_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "executionInfo": {
     "elapsed": 486,
     "status": "ok",
     "timestamp": 1683028918952,
     "user": {
      "displayName": "pantech e learning",
      "userId": "02085171050783995221"
     },
     "user_tz": -330
    },
    "id": "6od7g-Df_DWZ",
    "outputId": "eca9e337-d0ae-4ed9-d32e-5baa666e1ab0"
   },
   "outputs": [],
   "source": [
    "train_sample_metadata.groupby('label')['label'].count().plot(figsize=(5,5),kind='bar',title='The Label in the Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1683028922137,
     "user": {
      "displayName": "pantech e learning",
      "userId": "02085171050783995221"
     },
     "user_tz": -330
    },
    "id": "07BcrUmD_DWa",
    "outputId": "434514c5-ba27-472c-9612-93ad634fa51a"
   },
   "outputs": [],
   "source": [
    "train_sample_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1683028924739,
     "user": {
      "displayName": "pantech e learning",
      "userId": "02085171050783995221"
     },
     "user_tz": -330
    },
    "id": "NiKU2Zg-_DWd",
    "outputId": "6f3fac82-8dde-4e68-a7ee-0817572be875"
   },
   "outputs": [],
   "source": [
    "f_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='FAKE'].sample(5).index)\n",
    "f_train_sample_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXwVSsdw_DWg"
   },
   "outputs": [],
   "source": [
    "def capture_image_from_video():\n",
    "    capture_image = cv2.VideoCapture(r\"path\\of\\video\")\n",
    "    ret, frame = capture_image.read()\n",
    "    fig = plt.figure(figsize =(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 713,
     "status": "error",
     "timestamp": 1683028948419,
     "user": {
      "displayName": "pantech e learning",
      "userId": "02085171050783995221"
     },
     "user_tz": -330
    },
    "id": "lN2sKQge_DWh",
    "outputId": "c5717c57-5746-45a9-96de-61ce6bd61ca6"
   },
   "outputs": [],
   "source": [
    "capture_image_from_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 663,
     "status": "ok",
     "timestamp": 1680933088974,
     "user": {
      "displayName": "pantech e learning",
      "userId": "02085171050783995221"
     },
     "user_tz": -330
    },
    "id": "hV3neVRx_DWk",
    "outputId": "c5d8a42d-c749-4d7e-b459-065264b6c803"
   },
   "outputs": [],
   "source": [
    "r_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='REAL'].sample(1).index)\n",
    "r_train_sample_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nAeIgL7_DWn"
   },
   "outputs": [],
   "source": [
    "f_videos = list(train_sample_metadata.loc[train_sample_metadata.label=='FAKE'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "error",
     "timestamp": 1683029706093,
     "user": {
      "displayName": "pantech e learning",
      "userId": "02085171050783995221"
     },
     "user_tz": -330
    },
    "id": "EcWOZ5BF_DWo",
    "outputId": "d71ddd7a-0356-496d-c5cf-e7b863db246a"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def play_video(video_file,subset=TRAIN_SAMPLE_FOLDER):\n",
    "    video_url = open(os.path.join(DATA_FOLDER,subset,video_file),'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(video_url).decode()\n",
    "    return HTML(\"\"\"<video width=500 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" %data_url)\n",
    "play_video(f_videos[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raTloMeu_DWq"
   },
   "source": [
    "**Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtJ8lXBC_DWq"
   },
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 64\n",
    "epochs = 70\n",
    "\n",
    "max_seq_length = 20\n",
    "num_features = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLUHaqVq_DWr"
   },
   "outputs": [],
   "source": [
    "def crop_center_square(frame):\n",
    "    y,x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y :start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(img_size, img_size)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while 1:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "            \n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W86UKT9e_DWr",
    "outputId": "6e06da1e-9bb8-4bd0-a1b1-fd5c5e8bd6a6"
   },
   "outputs": [],
   "source": [
    "def pretrain_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "    weights = \"imagenet\",\n",
    "    include_top=False,\n",
    "    pooling=\"avg\",\n",
    "    input_shape = (img_size,img_size,3)\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    \n",
    "    inputs = keras.Input((img_size,img_size,3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "    \n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "feature_extractor = pretrain_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpsI-Kwa_DWs"
   },
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir): #df是train_sample_metadata->json的split\n",
    "    num_samples = len(df)\n",
    "    video_paths = list(df.index)\n",
    "    labels = df[\"label\"].values\n",
    "    labels = np.array(labels=='FAKE').astype(int)\n",
    "    \n",
    "    frame_masks = np.zeros(shape=(num_samples, max_seq_length), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, max_seq_length, num_features), dtype=\"float32\"\n",
    "    )\n",
    "    \n",
    "    for idx, path in enumerate(video_paths):\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "        \n",
    "        temp_frame_mask = np.zeros(shape=(1, max_seq_length,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(shape=(1, max_seq_length, num_features), dtype=\"float32\")\n",
    "        \n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(max_seq_length, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] =feature_extractor.predict(batch[None, j, :])\n",
    "            temp_frame_mask[i, :length] =1 # 1 = not masked, 0 = masked\n",
    "        \n",
    "        frame_features[idx,] =temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] =temp_frame_mask.squeeze()\n",
    "    \n",
    "    return (frame_features, frame_masks), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYzFP5oD_DWt",
    "outputId": "62e46cd5-a05d-45c3-d9a4-dfc077fa4c5d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_set , Test_set = train_test_split(train_sample_metadata, test_size=0.1,random_state=42,\n",
    "                                       stratify=train_sample_metadata['label'])\n",
    "print(Train_set.shape, Test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixrA-XMV_DWu",
    "outputId": "ace7d4de-300d-49ba-f796-e9018ba1e5bb"
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = prepare_all_videos(Train_set, \"train\")\n",
    "test_data, test_labels = prepare_all_videos(Test_set, \"test\")\n",
    "\n",
    "print(f\"Frame features in train set:{train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set:{train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwnJYk5L_DWv",
    "outputId": "e3a43ba7-f0df-4466-ebc3-957cab3a1171"
   },
   "outputs": [],
   "source": [
    "frame_features_input = keras.Input((max_seq_length, num_features))\n",
    "mask_input = keras.Input((max_seq_length,),dtype=\"bool\")\n",
    "\n",
    "x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask = mask_input)\n",
    "x = keras.layers.GRU(8)(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model([frame_features_input, mask_input], output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yezTcFwe_DWv",
    "outputId": "73fcfe73-52d1-40de-a030-50f0418a94eb"
   },
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint('./best_model.weights.h5', save_weights_only=True, save_best_only=True)\n",
    "history = model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_data=([test_data[0], test_data[1]], test_labels),\n",
    "        callbacks=[checkpoint],\n",
    "        epochs=epochs,\n",
    "        batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2q_l5lJR_DWx"
   },
   "outputs": [],
   "source": [
    "test_videos = pd.DataFrame(list(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER))), columns=['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdqphrjT_DWx",
    "outputId": "1b503a75-07a8-4dd8-fba3-bb022f531b20",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, max_seq_length,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, max_seq_length, num_features), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(max_seq_length, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  #  Updates the mask to 1 for all valid frames, indicating that those frames contain meaningful data (\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    frames = load_video(os.path.join(DATA_FOLDER, TEST_FOLDER,path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    return model.predict([frame_features, frame_mask])[0]\n",
    "    \n",
    "# This utility is for visualization.\n",
    "# Referenced from:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def to_gif(images):\n",
    "    converted_images = images.astype(np.uint8)\n",
    "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
    "    return embed.embed_file(\"animation.gif\")\n",
    "\n",
    "\n",
    "test_video = np.random.choice(test_videos[\"video\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "if(sequence_prediction(test_video)>=0.5):\n",
    "    print(f'The predicted class of the video is FAKE')\n",
    "else:\n",
    "    print(f'The predicted class of the video is REAL')\n",
    "\n",
    "play_video(test_video,TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, max_seq_length,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, max_seq_length, num_features), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(max_seq_length, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    frames = load_video(os.path.join(DATA_FOLDER, TEST_FOLDER,path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    return model.predict([frame_features, frame_mask])[0]\n",
    "    \n",
    "# This utility is for visualization.\n",
    "# Referenced from:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def to_gif(images):\n",
    "    converted_images = images.astype(np.uint8)\n",
    "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
    "    return embed.embed_file(\"animation.gif\")\n",
    "\n",
    "\n",
    "test_video = 'bwbp1.mp4'\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "if(sequence_prediction(test_video)>=0.5):\n",
    "    print(f'The predicted class of the video is REAL')\n",
    "else:\n",
    "    print(f'The predicted class of the video is FAKE')\n",
    "\n",
    "play_video(test_video,TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "#To create a simple LSTM model that predicts the next number in a sequence based on the previous numbers.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate a sine wave sequence\n",
    "def create_sequence(length):\n",
    "    x = np.linspace(0, 50, length)\n",
    "    y = np.sin(x)\n",
    "    return y\n",
    "\n",
    "# Generate a sequence of 1000 values\n",
    "sequence_length = 1000\n",
    "sequence = create_sequence(sequence_length)\n",
    "\n",
    "# Plot the sequence\n",
    "plt.plot(sequence)\n",
    "plt.show()\n",
    "\n",
    "# Prepare the dataset\n",
    "def create_dataset(sequence, look_back=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequence)-look_back-1):\n",
    "        X.append(sequence[i:(i+look_back)])\n",
    "        y.append(sequence[i + look_back])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set look-back period (how many previous values to consider)\n",
    "look_back = 5\n",
    "\n",
    "# Prepare the dataset\n",
    "X, y = create_dataset(sequence, look_back)\n",
    "\n",
    "# Reshape X for LSTM [samples, time steps, features]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Build the LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(look_back, 1)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=20, batch_size=32)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the original sequence and predictions\n",
    "plt.plot(sequence[look_back:], label=\"True Sequence\")\n",
    "plt.plot(predictions, label=\"Predicted Sequence\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
